{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# grid search cnn for monthly airline passengers dataset\n", 
        "from math import sqrt\n", 
        "from numpy import array\n", 
        "from numpy import mean\n", 
        "from pandas import DataFrame\n", 
        "from pandas import concat\n", 
        "from pandas import read_csv\n", 
        "import warnings\n", 
        "warnings.simplefilter(\"ignore\")\n", 
        "from sklearn.metrics import mean_squared_error\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "import tensorflow.python.util.deprecation as deprecation\n", 
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers.convolutional import Conv1D\n", 
        "from keras.layers.convolutional import MaxPooling1D\n", 
        "\n", 
        "# split a univariate dataset into train/test sets\n", 
        "def train_test_split(data, n_test):\n", 
        "\treturn data[:-n_test], data[-n_test:]\n", 
        "\n", 
        "# transform list into supervised learning format\n", 
        "def series_to_supervised(data, n_in, n_out=1):\n", 
        "\tdf = DataFrame(data)\n", 
        "\tcols = list()\n", 
        "\t# input sequence (t-n, ... t-1)\n", 
        "\tfor i in range(n_in, 0, -1):\n", 
        "\t\tcols.append(df.shift(i))\n", 
        "\t# forecast sequence (t, t+1, ... t+n)\n", 
        "\tfor i in range(0, n_out):\n", 
        "\t\tcols.append(df.shift(-i))\n", 
        "\t# put it all together\n", 
        "\tagg = concat(cols, axis=1)\n", 
        "\t# drop rows with NaN values\n", 
        "\tagg.dropna(inplace=True)\n", 
        "\treturn agg.values\n", 
        "\n", 
        "# root mean squared error or rmse\n", 
        "def measure_rmse(actual, predicted):\n", 
        "\treturn sqrt(mean_squared_error(actual, predicted))\n", 
        "\n", 
        "# difference dataset\n", 
        "def difference(data, order):\n", 
        "\treturn [data[i] - data[i - order] for i in range(order, len(data))]\n", 
        "\n", 
        "# fit a model\n", 
        "def model_fit(train, config):\n", 
        "\t# unpack config\n", 
        "\tn_input, n_filters, n_kernel, n_epochs, n_batch, n_diff = config\n", 
        "\t# prepare data\n", 
        "\tif n_diff > 0:\n", 
        "\t\ttrain = difference(train, n_diff)\n", 
        "\t# transform series into supervised format\n", 
        "\tdata = series_to_supervised(train, n_in=n_input)\n", 
        "\t# separate inputs and outputs\n", 
        "\ttrain_x, train_y = data[:, :-1], data[:, -1]\n", 
        "\t# reshape input data into [samples, timesteps, features]\n", 
        "\tn_features = 1\n", 
        "\ttrain_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n", 
        "\t# define model\n", 
        "\tmodel = Sequential()\n", 
        "\tmodel.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, n_features)))\n", 
        "\tmodel.add(MaxPooling1D(pool_size=2))\n", 
        "\tmodel.add(Flatten())\n", 
        "\tmodel.add(Dense(1))\n", 
        "\tmodel.compile(loss='mse', optimizer='adam')\n", 
        "\t# fit\n", 
        "\tmodel.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n", 
        "\treturn model\n", 
        "\n", 
        "# forecast with the fit model\n", 
        "def model_predict(model, history, config):\n", 
        "\t# unpack config\n", 
        "\tn_input, _, _, _, _, n_diff = config\n", 
        "\t# prepare data\n", 
        "\tcorrection = 0.0\n", 
        "\tif n_diff > 0:\n", 
        "\t\tcorrection = history[-n_diff]\n", 
        "\t\thistory = difference(history, n_diff)\n", 
        "\tx_input = array(history[-n_input:]).reshape((1, n_input, 1))\n", 
        "\t# forecast\n", 
        "\tyhat = model.predict(x_input, verbose=0)\n", 
        "\treturn correction + yhat[0]\n", 
        "\n", 
        "# walk-forward validation for univariate data\n", 
        "def walk_forward_validation(data, n_test, cfg):\n", 
        "\tpredictions = list()\n", 
        "\t# split dataset\n", 
        "\ttrain, test = train_test_split(data, n_test)\n", 
        "\t# fit model\n", 
        "\tmodel = model_fit(train, cfg)\n", 
        "\t# seed history with training dataset\n", 
        "\thistory = [x for x in train]\n", 
        "\t# step over each time-step in the test set\n", 
        "\tfor i in range(len(test)):\n", 
        "\t\t# fit model and make forecast for history\n", 
        "\t\tyhat = model_predict(model, history, cfg)\n", 
        "\t\t# store forecast in list of predictions\n", 
        "\t\tpredictions.append(yhat)\n", 
        "\t\t# add actual observation to history for the next loop\n", 
        "\t\thistory.append(test[i])\n", 
        "\t# estimate prediction error\n", 
        "\terror = measure_rmse(test, predictions)\n", 
        "\tprint(' > %.3f' % error)\n", 
        "\treturn error\n", 
        "\n", 
        "# score a model, return None on failure\n", 
        "def repeat_evaluate(data, config, n_test, n_repeats=10):\n", 
        "\t# convert config to a key\n", 
        "\tkey = str(config)\n", 
        "\t# fit and evaluate the model n times\n", 
        "\tscores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n", 
        "\t# summarize score\n", 
        "\tresult = mean(scores)\n", 
        "\tprint('> Model[%s] %.3f' % (key, result))\n", 
        "\treturn (key, result)\n", 
        "\n", 
        "# grid search configs\n", 
        "def grid_search(data, cfg_list, n_test):\n", 
        "\t# evaluate configs\n", 
        "\tscores = scores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n", 
        "\t# sort configs by error, asc\n", 
        "\tscores.sort(key=lambda tup: tup[1])\n", 
        "\treturn scores\n", 
        "\n", 
        "# create a list of configs to try\n", 
        "def model_configs():\n", 
        "\t# define scope of configs\n", 
        "\tn_input = [12]\n", 
        "\tn_filters = [64]\n", 
        "\tn_kernels = [3, 5]\n", 
        "\tn_epochs = [100]\n", 
        "\tn_batch = [1, 150]\n", 
        "\tn_diff = [0, 12]\n", 
        "\t# create configs\n", 
        "\tconfigs = list()\n", 
        "\tfor a in n_input:\n", 
        "\t\tfor b in n_filters:\n", 
        "\t\t\tfor c in n_kernels:\n", 
        "\t\t\t\tfor d in n_epochs:\n", 
        "\t\t\t\t\tfor e in n_batch:\n", 
        "\t\t\t\t\t\tfor f in n_diff:\n", 
        "\t\t\t\t\t\t\tcfg = [a,b,c,d,e,f]\n", 
        "\t\t\t\t\t\t\tconfigs.append(cfg)\n", 
        "\tprint('Total configs: %d' % len(configs))\n", 
        "\treturn configs\n", 
        "\n", 
        "# define dataset\n", 
        "series = read_csv('monthly-airline-passengers.csv', header=0, index_col=0)\n", 
        "data = series.values\n", 
        "# data split\n", 
        "n_test = 12\n", 
        "# model configs\n", 
        "cfg_list = model_configs()\n", 
        "# grid search\n", 
        "scores = grid_search(data, cfg_list, n_test)\n", 
        "print('done')\n", 
        "# list top 10 configs\n", 
        "for cfg, error in scores[:3]:\n", 
        "\tprint(cfg, error)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}
{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# multi-headed cnn model for the har dataset\n", 
        "from numpy import mean\n", 
        "from numpy import std\n", 
        "from numpy import dstack\n", 
        "from pandas import read_csv\n", 
        "import warnings\n", 
        "warnings.simplefilter(\"ignore\")\n", 
        "from keras.utils import to_categorical\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "from keras.models import Model\n", 
        "from keras.layers import Input\n", 
        "from keras.layers import Dense\n", 
        "import tensorflow.python.util.deprecation as deprecation\n", 
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers.convolutional import Conv1D\n", 
        "from keras.layers.convolutional import MaxPooling1D\n", 
        "from keras.layers.merge import concatenate\n", 
        "\n", 
        "# load a single file as a numpy array\n", 
        "def load_file(filepath):\n", 
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n", 
        "\treturn dataframe.values\n", 
        "\n", 
        "# load a list of files and return as a 3d numpy array\n", 
        "def load_group(filenames, prefix=''):\n", 
        "\tloaded = list()\n", 
        "\tfor name in filenames:\n", 
        "\t\tdata = load_file(prefix + name)\n", 
        "\t\tloaded.append(data)\n", 
        "\t# stack group so that features are the 3rd dimension\n", 
        "\tloaded = dstack(loaded)\n", 
        "\treturn loaded\n", 
        "\n", 
        "# load a dataset group, such as train or test\n", 
        "def load_dataset_group(group, prefix=''):\n", 
        "\tfilepath = prefix + group + '/Inertial Signals/'\n", 
        "\t# load all 9 files as a single array\n", 
        "\tfilenames = list()\n", 
        "\t# total acceleration\n", 
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n", 
        "\t# body acceleration\n", 
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n", 
        "\t# body gyroscope\n", 
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n", 
        "\t# load input data\n", 
        "\tX = load_group(filenames, filepath)\n", 
        "\t# load class output\n", 
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n", 
        "\treturn X, y\n", 
        "\n", 
        "# load the dataset, returns train and test X and y elements\n", 
        "def load_dataset(prefix=''):\n", 
        "\t# load all train\n", 
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n", 
        "\t# load all test\n", 
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n", 
        "\t# zero-offset class values\n", 
        "\ttrainy = trainy - 1\n", 
        "\ttesty = testy - 1\n", 
        "\t# one hot encode y\n", 
        "\ttrainy = to_categorical(trainy)\n", 
        "\ttesty = to_categorical(testy)\n", 
        "\treturn trainX, trainy, testX, testy\n", 
        "\n", 
        "# fit and evaluate a model\n", 
        "def evaluate_model(trainX, trainy, testX, testy):\n", 
        "\tverbose, epochs, batch_size = 0, 3, 32\n", 
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n", 
        " \t# head 1\n", 
        "\tinputs1 = Input(shape=(n_timesteps,n_features))\n", 
        "\tconv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs1)\n", 
        "\tdrop1 = Dropout(0.5)(conv1)\n", 
        "\tpool1 = MaxPooling1D(pool_size=2)(drop1)\n", 
        "\tflat1 = Flatten()(pool1)\n", 
        "\t# head 2\n", 
        "\tinputs2 = Input(shape=(n_timesteps,n_features))\n", 
        "\tconv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(inputs2)\n", 
        "\tdrop2 = Dropout(0.5)(conv2)\n", 
        "\tpool2 = MaxPooling1D(pool_size=2)(drop2)\n", 
        "\tflat2 = Flatten()(pool2)\n", 
        "\t# head 3\n", 
        "\tinputs3 = Input(shape=(n_timesteps,n_features))\n", 
        "\tconv3 = Conv1D(filters=64, kernel_size=11, activation='relu')(inputs3)\n", 
        "\tdrop3 = Dropout(0.5)(conv3)\n", 
        "\tpool3 = MaxPooling1D(pool_size=2)(drop3)\n", 
        "\tflat3 = Flatten()(pool3)\n", 
        "\t# merge\n", 
        "\tmerged = concatenate([flat1, flat2, flat3])\n", 
        "\t# interpretation\n", 
        "\tdense1 = Dense(100, activation='relu')(merged)\n", 
        "\toutputs = Dense(n_outputs, activation='softmax')(dense1)\n", 
        "\tmodel = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n", 
        "\t# save a plot of the model\n", 
        "\t# plot_model(model, show_shapes=True, to_file='multiheaded.png')\n", 
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", 
        "\t# fit network\n", 
        "\tmodel.fit([trainX,trainX,trainX], trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n", 
        "\t# evaluate model\n", 
        "\t_, accuracy = model.evaluate([testX,testX,testX], testy, batch_size=batch_size, verbose=0)\n", 
        "\treturn accuracy\n", 
        "\n", 
        "# summarize scores\n", 
        "def summarize_results(scores):\n", 
        "\tprint(scores)\n", 
        "\tm, s = mean(scores), std(scores)\n", 
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n", 
        "\n", 
        "# run an experiment\n", 
        "def run_experiment(repeats=3):\n", 
        "\t# load data\n", 
        "\ttrainX, trainy, testX, testy = load_dataset()\n", 
        "\t# repeat experiment\n", 
        "\tscores = list()\n", 
        "\tfor r in range(repeats):\n", 
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n", 
        "\t\tscore = score * 100.0\n", 
        "\t\tprint('>#%d: %.3f' % (r+1, score))\n", 
        "\t\tscores.append(score)\n", 
        "\t# summarize results\n", 
        "\tsummarize_results(scores)\n", 
        "\n", 
        "# run the experiment\n", 
        "run_experiment()"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}
{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# cnn model with filters for the har dataset\n", 
        "from numpy import mean\n", 
        "from numpy import std\n", 
        "from numpy import dstack\n", 
        "from pandas import read_csv\n", 
        "import warnings\n", 
        "warnings.simplefilter(\"ignore\")\n", 
        "%matplotlib inline\n", 
        "from matplotlib import pyplot\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "import tensorflow.python.util.deprecation as deprecation\n", 
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n", 
        "from keras.layers import Flatten\n", 
        "from keras.layers import Dropout\n", 
        "from keras.layers.convolutional import Conv1D\n", 
        "from keras.layers.convolutional import MaxPooling1D\n", 
        "from keras.utils import to_categorical\n", 
        "\n", 
        "# load a single file as a numpy array\n", 
        "def load_file(filepath):\n", 
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n", 
        "\treturn dataframe.values\n", 
        "\n", 
        "# load a list of files and return as a 3d numpy array\n", 
        "def load_group(filenames, prefix=''):\n", 
        "\tloaded = list()\n", 
        "\tfor name in filenames:\n", 
        "\t\tdata = load_file(prefix + name)\n", 
        "\t\tloaded.append(data)\n", 
        "\t# stack group so that features are the 3rd dimension\n", 
        "\tloaded = dstack(loaded)\n", 
        "\treturn loaded\n", 
        "\n", 
        "# load a dataset group, such as train or test\n", 
        "def load_dataset_group(group, prefix=''):\n", 
        "\tfilepath = prefix + group + '/Inertial Signals/'\n", 
        "\t# load all 9 files as a single array\n", 
        "\tfilenames = list()\n", 
        "\t# total acceleration\n", 
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n", 
        "\t# body acceleration\n", 
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n", 
        "\t# body gyroscope\n", 
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n", 
        "\t# load input data\n", 
        "\tX = load_group(filenames, filepath)\n", 
        "\t# load class output\n", 
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n", 
        "\treturn X, y\n", 
        "\n", 
        "# load the dataset, returns train and test X and y elements\n", 
        "def load_dataset(prefix=''):\n", 
        "\t# load all train\n", 
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n", 
        "\t# load all test\n", 
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n", 
        "\t# zero-offset class values\n", 
        "\ttrainy = trainy - 1\n", 
        "\ttesty = testy - 1\n", 
        "\t# one hot encode y\n", 
        "\ttrainy = to_categorical(trainy)\n", 
        "\ttesty = to_categorical(testy)\n", 
        "\treturn trainX, trainy, testX, testy\n", 
        "\n", 
        "# fit and evaluate a model\n", 
        "def evaluate_model(trainX, trainy, testX, testy, n_filters):\n", 
        "\tverbose, epochs, batch_size = 0, 3, 32\n", 
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n", 
        "\tmodel = Sequential()\n", 
        "\tmodel.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n", 
        "\tmodel.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu'))\n", 
        "\tmodel.add(Dropout(0.5))\n", 
        "\tmodel.add(MaxPooling1D(pool_size=2))\n", 
        "\tmodel.add(Flatten())\n", 
        "\tmodel.add(Dense(100, activation='relu'))\n", 
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n", 
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", 
        "\t# fit network\n", 
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n", 
        "\t# evaluate model\n", 
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n", 
        "\treturn accuracy\n", 
        "\n", 
        "# summarize scores\n", 
        "def summarize_results(scores, params):\n", 
        "\tprint(scores, params)\n", 
        "\t# summarize mean and standard deviation\n", 
        "\tfor i in range(len(scores)):\n", 
        "\t\tm, s = mean(scores[i]), std(scores[i])\n", 
        "\t\tprint('Param=%d: %.3f%% (+/-%.3f)' % (params[i], m, s))\n", 
        "\t# boxplot of scores\n", 
        "\tpyplot.boxplot(scores, labels=params)\n", 
        "\tpyplot.savefig('exp_cnn_filters.png')\n", 
        "\n", 
        "# run an experiment\n", 
        "def run_experiment(params, repeats=3):\n", 
        "\t# load data\n", 
        "\ttrainX, trainy, testX, testy = load_dataset()\n", 
        "\t# test each parameter\n", 
        "\tall_scores = list()\n", 
        "\tfor p in params:\n", 
        "\t\t# repeat experiment\n", 
        "\t\tscores = list()\n", 
        "\t\tfor r in range(repeats):\n", 
        "\t\t\tscore = evaluate_model(trainX, trainy, testX, testy, p)\n", 
        "\t\t\tscore = score * 100.0\n", 
        "\t\t\tprint('>p=%d #%d: %.3f' % (p, r+1, score))\n", 
        "\t\t\tscores.append(score)\n", 
        "\t\tall_scores.append(scores)\n", 
        "\t# summarize results\n", 
        "\tsummarize_results(all_scores, params)\n", 
        "\n", 
        "# run the experiment\n", 
        "n_params = [8, 16, 32, 64, 128, 256]\n", 
        "run_experiment(n_params)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}
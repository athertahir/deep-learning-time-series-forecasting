{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "# spot check on raw data from the har dataset\n", 
        "from numpy import dstack\n", 
        "from pandas import read_csv\n", 
        "import warnings\n", 
        "warnings.simplefilter(\"ignore\")\n", 
        "from sklearn.metrics import accuracy_score\n", 
        "from sklearn.neighbors import KNeighborsClassifier\n", 
        "from sklearn.tree import DecisionTreeClassifier\n", 
        "from sklearn.svm import SVC\n", 
        "from sklearn.naive_bayes import GaussianNB\n", 
        "from sklearn.ensemble import BaggingClassifier\n", 
        "from sklearn.ensemble import RandomForestClassifier\n", 
        "from sklearn.ensemble import ExtraTreesClassifier\n", 
        "from sklearn.ensemble import GradientBoostingClassifier\n", 
        "\n", 
        "# load a single file as a numpy array\n", 
        "def load_file(filepath):\n", 
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n", 
        "\treturn dataframe.values\n", 
        "\n", 
        "# load a list of files into a 3D array of [samples, timesteps, features]\n", 
        "def load_group(filenames, prefix=''):\n", 
        "\tloaded = list()\n", 
        "\tfor name in filenames:\n", 
        "\t\tdata = load_file(prefix + name)\n", 
        "\t\tloaded.append(data)\n", 
        "\t# stack group so that features are the 3rd dimension\n", 
        "\tloaded = dstack(loaded)\n", 
        "\treturn loaded\n", 
        "\n", 
        "# load a dataset group, such as train or test\n", 
        "def load_dataset_group(group, prefix=''):\n", 
        "\tfilepath = prefix + group + '/Inertial Signals/'\n", 
        "\t# load all 9 files as a single array\n", 
        "\tfilenames = list()\n", 
        "\t# total acceleration\n", 
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n", 
        "\t# body acceleration\n", 
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n", 
        "\t# body gyroscope\n", 
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n", 
        "\t# load input data\n", 
        "\tX = load_group(filenames, filepath)\n", 
        "\t# load class output\n", 
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n", 
        "\treturn X, y\n", 
        "\n", 
        "# load the dataset, returns train and test X and y elements\n", 
        "def load_dataset(prefix=''):\n", 
        "\t# load all train\n", 
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n", 
        "\t# load all test\n", 
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n", 
        "\t# flatten X\n", 
        "\ttrainX = trainX.reshape((trainX.shape[0], trainX.shape[1] * trainX.shape[2]))\n", 
        "\ttestX = testX.reshape((testX.shape[0], testX.shape[1] * testX.shape[2]))\n", 
        "\t# flatten y\n", 
        "\ttrainy, testy = trainy[:,0], testy[:,0]\n", 
        "\treturn trainX, trainy, testX, testy\n", 
        "\n", 
        "# create a dict of standard models to evaluate {name:object}\n", 
        "def define_models(models=dict()):\n", 
        "\t# nonlinear models\n", 
        "\tmodels['knn'] = KNeighborsClassifier(n_neighbors=7)\n", 
        "\tmodels['cart'] = DecisionTreeClassifier()\n", 
        "\tmodels['svm'] = SVC()\n", 
        "\tmodels['bayes'] = GaussianNB()\n", 
        "\t# ensemble models\n", 
        "\tmodels['bag'] = BaggingClassifier(n_estimators=10)\n", 
        "\tmodels['rf'] = RandomForestClassifier(n_estimators=10)\n", 
        "\tmodels['et'] = ExtraTreesClassifier(n_estimators=10)\n", 
        "\tmodels['gbm'] = GradientBoostingClassifier(n_estimators=10)\n", 
        "\tprint('Defined %d models' % len(models))\n", 
        "\treturn models\n", 
        "\n", 
        "# evaluate a single model\n", 
        "def evaluate_model(trainX, trainy, testX, testy, model):\n", 
        "\t# fit the model\n", 
        "\tmodel.fit(trainX, trainy)\n", 
        "\t# make predictions\n", 
        "\tyhat = model.predict(testX)\n", 
        "\t# evaluate predictions\n", 
        "\taccuracy = accuracy_score(testy, yhat)\n", 
        "\treturn accuracy * 100.0\n", 
        "\n", 
        "# evaluate a dict of models {name:object}, returns {name:score}\n", 
        "def evaluate_models(trainX, trainy, testX, testy, models):\n", 
        "\tresults = dict()\n", 
        "\tfor name, model in models.items():\n", 
        "\t\t# evaluate the model\n", 
        "\t\tresults[name] = evaluate_model(trainX, trainy, testX, testy, model)\n", 
        "\t\t# show process\n", 
        "\t\tprint('>%s: %.3f' % (name, results[name]))\n", 
        "\treturn results\n", 
        "\n", 
        "# print and plot the results\n", 
        "def summarize_results(results, maximize=True):\n", 
        "\t# create a list of (name, mean(scores)) tuples\n", 
        "\tmean_scores = [(k,v) for k,v in results.items()]\n", 
        "\t# sort tuples by mean score\n", 
        "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n", 
        "\t# reverse for descending order (e.g. for accuracy)\n", 
        "\tif maximize:\n", 
        "\t\tmean_scores = list(reversed(mean_scores))\n", 
        "\tprint()\n", 
        "\tfor name, score in mean_scores:\n", 
        "\t\tprint('Name=%s, Score=%.3f' % (name, score))\n", 
        "\n", 
        "# load dataset\n", 
        "trainX, trainy, testX, testy = load_dataset()\n", 
        "# get model list\n", 
        "models = define_models()\n", 
        "# evaluate models\n", 
        "results = evaluate_models(trainX, trainy, testX, testy, models)\n", 
        "# summarize results\n", 
        "summarize_results(results)"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}